{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Perceptum (MLP) <a name=\"multilayer\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use **Multilayer Perceptron (MLP)** because it is a flexible neural network architecture. MLPs are great for solving **classification problems**\n",
    "\n",
    "First, we will define the model architecture, this step consists in:\n",
    "- **Number of layers**\n",
    "- **Number of neurons of each layer**\n",
    "- **Choice of the activation functions**\n",
    "\n",
    "\n",
    "Then we'll perform the training strategy, this strategy includes:\n",
    "- **Optimizer**\n",
    "- **Learning hyperparameters** (e.g., learning rate, mini-batch size, number of epochs, etc.)\n",
    "- **Regularization techniques to adopt** (e.g., early stopping, weight regularization, dropout, data augmentation, etc.)\n",
    "- **Possibility of using transfer learning**\n",
    "\n",
    "The network works by processing data through **multiple layers**, with each layer learning to capture different features of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture definition <a name=\"architecture\"></a>\n",
    "[[go back to the top]](#multilayer)\n",
    "\n",
    "For the architecture of our MLP model we need, as mentioned above, the number of layers, neurons, and choose the activation functions such as relu, softmax and Tanh for example.\n",
    "\n",
    "\n",
    "The following table defines the our model architecture:\n",
    "\n",
    "| <span style=\"color: #C70039;\">**Architecture**</span> | <span style=\"color: #C70039;\">**Options**</span>  |\n",
    "|-----------------------------------------------------|-------------------------------------------------------|\n",
    "| <span style=\"color: #00bfae;\">**hidden_units**</span> | [[128, 64], [256, 128, 64], [64, 32]]               |\n",
    "| <span style=\"color: #00bfae;\">**Activation functions**</span> | ['relu', 'relu', 'tanh']                                  |   \n",
    "\n",
    "- **hidden_units** consists in the number of layers and the number of each neurons of each layer, for example in this case [256, 128, 64], it defines 3 layers with 256, 128 and 64 neurons, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"mlp_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"mlp_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m5,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,914</span> (62.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,914\u001b[0m (62.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,914</span> (62.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,914\u001b[0m (62.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pathos.multiprocessing import Pool\n",
    "\n",
    "# Classe para definir a arquitetura do modelo MLP\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self, input_dim, output_dim, hidden_units):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layers = []\n",
    "        for units in hidden_units:\n",
    "            self.hidden_layers.append(tf.keras.layers.Dense(units, activation='relu'))\n",
    "        self.output_layer = tf.keras.layers.Dense(output_dim, activation='softmax')  # Saída multi-classe\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(MLP, self).build(input_shape)\n",
    "        # Informar ao TensorFlow as dimensões esperadas das entradas\n",
    "        self.call(tf.keras.Input(shape=input_shape[1:]))\n",
    "\n",
    "\n",
    "input_dim = 40  # Exemplo: número de features\n",
    "output_dim = 10  # Exemplo: número de classes\n",
    "hidden_units = [128, 64, 32]\n",
    "\n",
    "model = MLP(input_dim=input_dim, output_dim=output_dim, hidden_units=hidden_units)\n",
    "\n",
    "# Construir o modelo explicitamente\n",
    "model.build((None, input_dim))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Strategy <a name=\"training\"></a>\n",
    "[[go back to the top]](#multilayer)\n",
    "\n",
    "We used **dictionaries** to organize and store different options for **hyperparameters**. This allows us to easily experiment with different configurations and manage the settings efficiently.\n",
    "\n",
    "To optimize our model, we decided to **update and select the best hyperparameter combination in the first iteration**. This means that in the beginning, we test several combinations of hyperparameters to find the one that performs best. By doing this, we can quickly narrow down the best model for our task, improving the **accuracy** of the predictions.\n",
    "\n",
    "Additionally, we will use the **ADAM** optimizer, which is a popular choice for training neural networks due to its adaptive learning rate and efficient performance.\n",
    "We also implemented **early stopping** to prevent overfitting by monitoring the model's performance and halting training when it stops improving.\n",
    "\n",
    "In this way, the process of **testing and updating** in the first iteration helps us fine-tune the model efficiently, and **selecting the best combination** ensures we are using the most effective settings for our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Hyperparameter Configuration\n",
    "\n",
    "The following table defines the possible combinations of hyperparameters we tested:\n",
    "\n",
    "| <span style=\"color: #C70039;\">**Hyperparameter**</span> | <span style=\"color: #C70039;\">**Options**</span>        |\n",
    "|-----------------------------------------------------|-------------------------------------------------------|\n",
    "| <span style=\"color: #00bfae;\">**hidden_units**</span> | [[128, 64], [256, 128, 64], [64, 32]]                 |\n",
    "| <span style=\"color: #00bfae;\">**dropout_rate**</span> | [0.3, 0.5]                                            |\n",
    "| <span style=\"color: #00bfae;\">**batch_size**</span>   | [32]                                                  |\n",
    "| <span style=\"color: #00bfae;\">**epochs**</span>       | [20]                                                  |\n",
    "| <span style=\"color: #00bfae;\">**learning_rate**</span> | [0.001, 0.0001]                                       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6380297541618347\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6655212044715881\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6735395193099976\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.636884331703186\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6666666865348816\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6758304834365845\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6449026465415955\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6529209613800049\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6907216310501099\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6975945234298706\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6792668700218201\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6414662003517151\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6998854279518127\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6632302403450012\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.648339033126831\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6586483120918274\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6838487982749939\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6471936106681824\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.7021763920783997\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6769759654998779\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6563574075698853\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6861397624015808\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6403207182884216\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6712485551834106\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6964490413665771\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6620847582817078\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6632302403450012\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6804123520851135\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6632302403450012\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6609392762184143\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6643757224082947Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6781214475631714\n",
      "\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.674685001373291\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6391752362251282\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6529209613800049\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6460481286048889\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6426116824150085\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6540664434432983\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6311569213867188\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6792668700218201\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6941580772399902\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.674685001373291\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.650629997253418\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6334478855133057\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6632302403450012\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.636884331703186\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6254295706748962\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6334478855133057\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6804123520851135\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6345933675765991\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6219931244850159\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6552119255065918\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6907216310501099\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6552119255065918\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6872852444648743\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6460481286048889\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.650629997253418\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.667812168598175\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.7044673562049866\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6265750527381897\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.7044673562049866\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.674685001373291\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6758304834365845\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6494845151901245\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6620847582817078\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6723940372467041\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6540664434432983\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6849942803382874\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6838487982749939\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.648339033126831\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6884307265281677\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6082473993301392\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6689575910568237\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6655212044715881\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.5773195624351501\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6643757224082947\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6975945234298706\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6449026465415955\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6540664434432983\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6380297541618347\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.612829327583313\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6552119255065918\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.667812168598175\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6655212044715881\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6884307265281677\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6964490413665771\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6838487982749939\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6838487982749939\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.643757164478302\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6941580772399902\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.643757164478302\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6907216310501099\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6918671131134033\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6689575910568237\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6838487982749939\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6323024034500122\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.7227949500083923\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6804123520851135\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6953035593032837\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6895761489868164\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6712485551834106\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6723940372467041\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6827033162117004\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.681557834148407\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.681557834148407\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.5498281717300415\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.5166093707084656\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6597937941551208\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6494845151901245\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6918671131134033\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6471936106681824\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6334478855133057\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.5601374506950378\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.7010309100151062\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.5498281717300415\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6723940372467041\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6769759654998779\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6907216310501099\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6609392762184143\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6426116824150085\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6380297541618347\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6494845151901245\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6529209613800049\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6723940372467041\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6792668700218201\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6712485551834106\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.667812168598175\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6792668700218201\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6254295706748962\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6300114393234253\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6265750527381897\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6345933675765991\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6449026465415955\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6552119255065918\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6517754793167114\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6758304834365845\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6655212044715881\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6254295706748962\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6872852444648743\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6838487982749939\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.681557834148407\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6620847582817078\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6689575910568237\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6345933675765991\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6426116824150085\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6907216310501099\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6586483120918274\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6941580772399902\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6540664434432983\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6735395193099976\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.70561283826828\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.7170675992965698\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6918671131134033\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6872852444648743\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.575028657913208\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6964490413665771\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6666666865348816\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.681557834148407\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6632302403450012\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.674685001373291\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6586483120918274\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6036655306816101\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6827033162117004\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6632302403450012\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6735395193099976\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6884307265281677\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6620847582817078\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6998854279518127\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.7010309100151062\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6872852444648743\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.7010309100151062\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6552119255065918\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6861397624015808\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6529209613800049\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.650629997253418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 11:49:55.790946: W tensorflow/core/framework/op_kernel.cc:1840] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: Expected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n",
      "2024-11-27 11:49:55.791240: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: INVALID_ARGUMENT: Expected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n",
      "\t [[{{function_node __inference_one_step_on_data_209295}}{{node strided_slice}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.648339033126831\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6895761489868164\n",
      "Configuration: {'hidden_units': [64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6620847582817078\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6918671131134033\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6597937941551208\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6941580772399902\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6953035593032837\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.674685001373291\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6471936106681824\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6380297541618347\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6930125951766968\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6254295706748962\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6849942803382874\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6449026465415955\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6460481286048889\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6655212044715881\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6872852444648743\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6849942803382874\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6288659572601318\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6884307265281677\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6323024034500122\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6827033162117004\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6426116824150085\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6494845151901245\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6666666865348816\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6941580772399902\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6781214475631714\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6265750527381897\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 32, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6563574075698853\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.6575028896331787\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.681557834148407\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6403207182884216\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.001} | Accuracy: 0.681557834148407\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6701030731201172\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6792668700218201\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.648339033126831\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6918671131134033\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6769759654998779\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6838487982749939\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6666666865348816\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 20, 'learning_rate': 0.0001} | Accuracy: 0.6620847582817078\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.1, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6987400054931641\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6563574075698853\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.2, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.6460481286048889\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001} | Accuracy: 0.6597937941551208\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.3, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.7101947069168091\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.4, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.7044673562049866\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'dropout_rate': 0.5, 'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001} | Accuracy: 0.650629997253418\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node strided_slice defined at (most recent call last):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 725, in start\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 106, in <module>\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 212, in __init__\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 303, in _repopulate_pool\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 326, in _repopulate_pool_static\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 121, in start\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/context.py\", line 277, in _Popen\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/popen_fork.py\", line 19, in __init__\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/popen_fork.py\", line 71, in _launch\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 108, in run\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 125, in worker\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 48, in mapstar\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 84, in evaluate_config_parallel\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 78, in cross_validate_model\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 54, in train_evaluate_model\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 62, in train_step\n\nExpected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n\t [[{{node strided_slice}}]] [Op:__inference_one_step_on_iterator_209348]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 84, in evaluate_config_parallel\n    accuracy = cross_validate_model(config, files, k=10)\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 78, in cross_validate_model\n    accuracy = train_evaluate_model(config, X_train, y_train, X_val, y_val)\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 54, in train_evaluate_model\n    history = model.fit(\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:\n\nDetected at node strided_slice defined at (most recent call last):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 725, in start\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 106, in <module>\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 212, in __init__\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 303, in _repopulate_pool\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 326, in _repopulate_pool_static\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 121, in start\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/context.py\", line 277, in _Popen\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/popen_fork.py\", line 19, in __init__\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/popen_fork.py\", line 71, in _launch\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 108, in run\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 125, in worker\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 48, in mapstar\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 84, in evaluate_config_parallel\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 78, in cross_validate_model\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 54, in train_evaluate_model\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 62, in train_step\n\nExpected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n\t [[{{node strided_slice}}]] [Op:__inference_one_step_on_iterator_209348]\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 107\u001b[0m\n\u001b[1;32m    105\u001b[0m num_workers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m--> 107\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_config_parallel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_configs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m# Encontrar a melhor configuração\u001b[39;00m\n\u001b[1;32m    110\u001b[0m best_config, best_accuracy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(results, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node strided_slice defined at (most recent call last):\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/runpy.py\", line 87, in _run_code\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel_launcher.py\", line 17, in <module>\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelapp.py\", line 725, in start\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/tornado/platform/asyncio.py\", line 215, in start\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n\n  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/asyncio/events.py\", line 80, in _run\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 513, in dispatch_queue\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 502, in process_one\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 409, in dispatch_shell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3016, in _run_cell\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3221, in run_cell_async\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3400, in run_ast_nodes\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 106, in <module>\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 212, in __init__\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 303, in _repopulate_pool\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 326, in _repopulate_pool_static\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 121, in start\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/context.py\", line 277, in _Popen\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/popen_fork.py\", line 19, in __init__\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/popen_fork.py\", line 71, in _launch\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 315, in _bootstrap\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/process.py\", line 108, in run\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 125, in worker\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/multiprocess/pool.py\", line 48, in mapstar\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 84, in evaluate_config_parallel\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 78, in cross_validate_model\n\n  File \"/var/folders/qx/kgqzhwb50b7flqgr05m062t40000gn/T/ipykernel_10906/1556981529.py\", line 54, in train_evaluate_model\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 320, in fit\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 121, in one_step_on_iterator\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 108, in one_step_on_data\n\n  File \"/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/backend/tensorflow/trainer.py\", line 62, in train_step\n\nExpected begin, end, and strides to be 1D equal size tensors, but got shapes [0], [1], and [1] instead.\n\t [[{{node strided_slice}}]] [Op:__inference_one_step_on_iterator_209348]"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pathos.multiprocessing import Pool\n",
    "\n",
    "# Classe MLP\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self, input_dim, output_dim, hidden_units, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layers = []\n",
    "        for units in hidden_units:\n",
    "            self.hidden_layers.append(tf.keras.layers.Dense(units, activation='relu'))\n",
    "            self.hidden_layers.append(tf.keras.layers.Dropout(dropout_rate))\n",
    "        self.output_layer = tf.keras.layers.Dense(output_dim, activation='softmax')  # Classificação multi-classe\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Gerar todas as combinações de hiperparâmetros\n",
    "def generate_configs(configurations):\n",
    "    keys, values = zip(*configurations.items())\n",
    "    return [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "# Função para carregar os dados de um fold específico\n",
    "def load_fold_data(fold_number, files):\n",
    "    data = pd.read_csv(files[fold_number])\n",
    "    labels = data.pop('Label').values  # Extrair os rótulos diretamente\n",
    "    features = data.values  # Extrair as features como matriz numpy\n",
    "    return features, labels\n",
    "\n",
    "# Treinar e avaliar o modelo\n",
    "def train_evaluate_model(config, X_train, y_train, X_val, y_val):\n",
    "    model = MLP(input_dim=X_train.shape[1],\n",
    "                output_dim=10,\n",
    "                hidden_units=config['hidden_units'],\n",
    "                dropout_rate=config['dropout_rate'])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=config['batch_size'],\n",
    "        epochs=config['epochs'],\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return max(history.history['val_accuracy'])  # Melhor acurácia na validação\n",
    "\n",
    "# Cross-validation, apenas a primeira iteração\n",
    "def cross_validate_model(config, files, k=10):\n",
    "    for i in range(k):\n",
    "        X_val, y_val = load_fold_data(i, files)\n",
    "        X_train, y_train = [], []\n",
    "        for j in range(k):\n",
    "            if j != i:\n",
    "                X_temp, y_temp = load_fold_data(j, files)\n",
    "                X_train.append(X_temp)\n",
    "                y_train.append(y_temp)\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "        accuracy = train_evaluate_model(config, X_train, y_train, X_val, y_val)\n",
    "        return accuracy  # Retorna após a primeira iteração\n",
    "\n",
    "# Função para avaliação em paralelo\n",
    "def evaluate_config_parallel(args):\n",
    "    config, files = args\n",
    "    accuracy = cross_validate_model(config, files, k=10)\n",
    "    print(f\"Configuration: {config} | Accuracy: {accuracy}\")\n",
    "    return config, accuracy\n",
    "\n",
    "# Definições de hiperparâmetros\n",
    "configurations = {\n",
    "    \"hidden_units\": [[128, 64, 32], [256, 128, 64], [64, 32],[512,256,128], [256,128,64,32]],\n",
    "    \"dropout_rate\": [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    \"batch_size\": [32,64],\n",
    "    \"epochs\": [20,50],\n",
    "    \"learning_rate\": [0.001, 0.0001]\n",
    "    \n",
    "}\n",
    "\n",
    "files = [f'datasets/urbansounds_features_fold{i}.csv' for i in range(1,11)] \n",
    "\n",
    "# Gerar todas as combinações de configurações\n",
    "all_configs = generate_configs(configurations)\n",
    "\n",
    "# Rodar tuning em paralelo\n",
    "if __name__ == '__main__':\n",
    "    num_workers = 8 #milas cores\n",
    "    with Pool(num_workers) as pool:\n",
    "        results = pool.map(evaluate_config_parallel, [(config, files) for config in all_configs])\n",
    "\n",
    "    # Encontrar a melhor configuração\n",
    "    best_config, best_accuracy = max(results, key=lambda x: x[1])\n",
    "    print(f\"Best configuration: {best_config}, Best accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eu tenho esta funcao eu quero que o modelo rode apenas uma vez o cross validation para testar apenas os parâmetros da arquitetura da rede, ou seja numero de leayer, neurónios por layer, e funcao de ativação \n",
    "quero fazer um grid search para ver quais as melhores combinações iniciais para comecar a arquitetura da rede \n",
    "apenas quero que seja feita 1 iteracao do cross validation para verificar qual delas é a melhor combinação \n",
    "\n",
    "\n",
    "\n",
    "neste momento estou a fazer grid search com o dropout learning rate etc mas eu apenas quero estes parâmetros numero de leayer, neurónios por layer, e funcao de ativação  nessa tal funcao de cross validation \n",
    "\n",
    "os outros valores tem de ser os standard, para que depois haja hyperparameter tuning durante o treino no MLP\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pathos.multiprocessing import Pool\n",
    "\n",
    "# Classe MLP\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self, input_dim, output_dim, hidden_units, dropout_rate):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layers = []\n",
    "        for units in hidden_units:\n",
    "            self.hidden_layers.append(tf.keras.layers.Dense(units, activation='relu'))\n",
    "            self.hidden_layers.append(tf.keras.layers.Dropout(dropout_rate))\n",
    "        self.output_layer = tf.keras.layers.Dense(output_dim, activation='softmax')  # Classificação multi-classe\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Gerar todas as combinações de hiperparâmetros\n",
    "def generate_configs(configurations):\n",
    "    keys, values = zip(*configurations.items())\n",
    "    return [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "# Função para carregar os dados de um fold específico\n",
    "def load_fold_data(fold_number, files):\n",
    "    data = pd.read_csv(files[fold_number])\n",
    "    labels = data.pop('Label').values  # Extrair os rótulos diretamente\n",
    "    features = data.values  # Extrair as features como matriz numpy\n",
    "    return features, labels\n",
    "\n",
    "# Treinar e avaliar o modelo\n",
    "def train_evaluate_model(config, X_train, y_train, X_val, y_val):\n",
    "    model = MLP(input_dim=X_train.shape[1],\n",
    "                output_dim=10,\n",
    "                hidden_units=config['hidden_units'],\n",
    "                dropout_rate=config['dropout_rate'])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=config['batch_size'],\n",
    "        epochs=config['epochs'],\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return max(history.history['val_accuracy'])  # Melhor acurácia na validação\n",
    "\n",
    "# Cross-validation, apenas a primeira iteração\n",
    "def cross_validate_model(config, files, k=10):\n",
    "    for i in range(k):\n",
    "        X_val, y_val = load_fold_data(i, files)\n",
    "        X_train, y_train = [], []\n",
    "        for j in range(k):\n",
    "            if j != i:\n",
    "                X_temp, y_temp = load_fold_data(j, files)\n",
    "                X_train.append(X_temp)\n",
    "                y_train.append(y_temp)\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "        accuracy = train_evaluate_model(config, X_train, y_train, X_val, y_val)\n",
    "        return accuracy  # Retorna após a primeira iteração\n",
    "\n",
    "# Função para avaliação em paralelo\n",
    "def evaluate_config_parallel(args):\n",
    "    config, files = args\n",
    "    accuracy = cross_validate_model(config, files, k=10)\n",
    "    print(f\"Configuration: {config} | Accuracy: {accuracy}\")\n",
    "    return config, accuracy\n",
    "\n",
    "# Definições de hiperparâmetros\n",
    "configurations = {\n",
    "    \"hidden_units\": [[128, 64, 32], [256, 128, 64], [64, 32],[512,256,128], [256,128,64,32]],\n",
    "    \"dropout_rate\": [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    \"batch_size\": [32,64],\n",
    "    \"epochs\": [20,50],\n",
    "    \"learning_rate\": [0.001, 0.0001]\n",
    "    \n",
    "}\n",
    "\n",
    "files = [f'datasets/urbansounds_features_fold{i}.csv' for i in range(1,11)] \n",
    "\n",
    "# Gerar todas as combinações de configurações\n",
    "all_configs = generate_configs(configurations)\n",
    "\n",
    "# Rodar tuning em paralelo\n",
    "if __name__ == '__main__':\n",
    "    num_workers = 8\n",
    "    with Pool(num_workers) as pool:\n",
    "        results = pool.map(evaluate_config_parallel, [(config, files) for config in all_configs])\n",
    "\n",
    "    # Encontrar a melhor configuração\n",
    "    best_config, best_accuracy = max(results, key=lambda x: x[1])\n",
    "    print(f\"Best configuration: {best_config}, Best accuracy: {best_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: {'hidden_units': [128, 64], 'activation': 'tanh'} | Accuracy: 0.6632302403450012\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'activation': 'tanh'} | Accuracy: 0.674685001373291\n",
      "Configuration: {'hidden_units': [128, 64], 'activation': 'relu'} | Accuracy: 0.6723940372467041\n",
      "Configuration: {'hidden_units': [256, 128, 64], 'activation': 'relu'} | Accuracy: 0.6334478855133057\n",
      "Configuration: {'hidden_units': [64, 32], 'activation': 'relu'} | Accuracy: 0.6597937941551208\n",
      "Configuration: {'hidden_units': [64, 32], 'activation': 'tanh'} | Accuracy: 0.6712485551834106\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'activation': 'relu'} | Accuracy: 0.636884331703186\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'activation': 'tanh'} | Accuracy: 0.6597937941551208\n",
      "Configuration: {'hidden_units': [256, 128, 64, 32], 'activation': 'relu'} | Accuracy: 0.6334478855133057\n",
      "Configuration: {'hidden_units': [512, 256, 128], 'activation': 'tanh'} | Accuracy: 0.6529209613800049\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'activation': 'tanh'} | Accuracy: 0.681557834148407\n",
      "Configuration: {'hidden_units': [128, 64, 32], 'activation': 'relu'} | Accuracy: 0.6586483120918274\n",
      "Best architecture: {'hidden_units': [128, 64, 32], 'activation': 'tanh'}, Best accuracy: 0.681557834148407\n",
      "Best tuning config: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001, 'dropout_rate': 0.1}, Best tuning accuracy: 0.7136311531066895\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from pathos.multiprocessing import Pool\n",
    "\n",
    "# Classe MLP\n",
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self, input_dim, output_dim, hidden_units, activation):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden_layers = [\n",
    "            tf.keras.layers.Dense(units, activation=activation)\n",
    "            for units in hidden_units\n",
    "        ]\n",
    "        self.output_layer = tf.keras.layers.Dense(output_dim, activation='softmax')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "# Gerar todas as combinações de hiperparâmetros\n",
    "def generate_configs(configurations):\n",
    "    keys, values = zip(*configurations.items())\n",
    "    return [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "# Função para carregar os dados de um fold específico\n",
    "def load_fold_data(fold_number, files):\n",
    "    data = pd.read_csv(files[fold_number])\n",
    "    labels = data.pop('Label').values\n",
    "    features = data.values\n",
    "    return features, labels\n",
    "\n",
    "# Treinar e avaliar o modelo\n",
    "def train_evaluate_model(config, X_train, y_train, X_val, y_val):\n",
    "    model = MLP(\n",
    "        input_dim=X_train.shape[1],\n",
    "        output_dim=10,\n",
    "        hidden_units=config['hidden_units'],\n",
    "        activation=config['activation']\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),  # Valor padrão\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=32,  # Valor padrão\n",
    "        epochs=20,      # Valor padrão\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return max(history.history['val_accuracy'])  # Melhor acurácia na validação\n",
    "\n",
    "# Cross-validation, apenas a primeira iteração\n",
    "def cross_validate_model(config, files, k=10):\n",
    "    X_val, y_val = load_fold_data(0, files)\n",
    "    X_train, y_train = [], []\n",
    "    for j in range(1, k):  # Exclui o fold de validação\n",
    "        X_temp, y_temp = load_fold_data(j, files)\n",
    "        X_train.append(X_temp)\n",
    "        y_train.append(y_temp)\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "    accuracy = train_evaluate_model(config, X_train, y_train, X_val, y_val)\n",
    "    return accuracy\n",
    "\n",
    "# Função para avaliação em paralelo\n",
    "def evaluate_config_parallel(args):\n",
    "    config, files = args\n",
    "    accuracy = cross_validate_model(config, files, k=10)\n",
    "    print(f\"Configuration: {config} | Accuracy: {accuracy}\")\n",
    "    return config, accuracy\n",
    "\n",
    "# Arquitetura inicial - Grid Search\n",
    "architecture_configs = {\n",
    "    \"hidden_units\": [[128, 64], [256, 128,64,], [64, 32], [512, 256, 128], [256, 128, 64, 32],[128,64,32]],\n",
    "    \"activation\": ['relu', 'tanh']\n",
    "}\n",
    "\n",
    "files = [f'datasets/urbansounds_features_fold{i}.csv' for i in range(1,11)]\n",
    "\n",
    "# Etapa 1: Encontrar a melhor arquitetura\n",
    "if __name__ == '__main__':\n",
    "    num_workers = 4\n",
    "    all_architecture_configs = generate_configs(architecture_configs)\n",
    "    \n",
    "    with Pool(num_workers) as pool:\n",
    "        architecture_results = pool.map(\n",
    "            evaluate_config_parallel,\n",
    "            [(config, files) for config in all_architecture_configs]\n",
    "        )\n",
    "    \n",
    "    best_architecture, best_arch_accuracy = max(\n",
    "        architecture_results, key=lambda x: x[1]\n",
    "    )\n",
    "    print(f\"Best architecture: {best_architecture}, Best accuracy: {best_arch_accuracy}\")\n",
    "    \n",
    "    # Etapa 2: Ajuste fino dos hiperparâmetros\n",
    "    tuning_configs = {\n",
    "        \"batch_size\": [16, 32, 64],\n",
    "        \"epochs\": [20, 50, 100],\n",
    "        \"learning_rate\": [0.001, 0.0001, 0.01],\n",
    "        \"dropout_rate\": [0.1, 0.2, 0.3, 0.5]\n",
    "    }\n",
    "    \n",
    "    all_tuning_configs = generate_configs(tuning_configs)\n",
    "    \n",
    "    def evaluate_tuning_config(args):\n",
    "        config, files = args\n",
    "        X_val, y_val = load_fold_data(0, files)\n",
    "        X_train, y_train = [], []\n",
    "        for j in range(1, 10):\n",
    "            X_temp, y_temp = load_fold_data(j, files)\n",
    "            X_train.append(X_temp)\n",
    "            y_train.append(y_temp)\n",
    "        X_train = np.concatenate(X_train, axis=0)\n",
    "        y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "        config_model = MLP(\n",
    "            input_dim=X_train.shape[1],\n",
    "            output_dim=10,\n",
    "            hidden_units=best_architecture['hidden_units'],  # Melhor arquitetura\n",
    "            activation=best_architecture['activation']\n",
    "        )\n",
    "        config_model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        history = config_model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_val, y_val),\n",
    "            batch_size=config['batch_size'],\n",
    "            epochs=config['epochs'],\n",
    "            verbose=0\n",
    "        )\n",
    "        accuracy = max(history.history['val_accuracy'])\n",
    "        return config, accuracy\n",
    "\n",
    "    # Rodar tuning em paralelo\n",
    "    with Pool(num_workers) as pool:\n",
    "        tuning_results = pool.map(\n",
    "            evaluate_tuning_config,\n",
    "            [(config, files) for config in all_tuning_configs]\n",
    "        )\n",
    "    \n",
    "    best_tuning_config, best_tuning_accuracy = max(\n",
    "        tuning_results, key=lambda x: x[1]\n",
    "    )\n",
    "    print(f\"Best tuning config: {best_tuning_config}, Best tuning accuracy: {best_tuning_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1790 - loss: 2.2603 - val_accuracy: 0.3093 - val_loss: 2.0903\n",
      "Epoch 2/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.3680 - loss: 2.0648 - val_accuracy: 0.4444 - val_loss: 1.9112\n",
      "Epoch 3/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.4151 - loss: 1.9054 - val_accuracy: 0.4662 - val_loss: 1.7642\n",
      "Epoch 4/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.4288 - loss: 1.7873 - val_accuracy: 0.4731 - val_loss: 1.6522\n",
      "Epoch 5/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - accuracy: 0.4630 - loss: 1.6734 - val_accuracy: 0.5132 - val_loss: 1.5542\n",
      "Epoch 6/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.4908 - loss: 1.5979 - val_accuracy: 0.5326 - val_loss: 1.4865\n",
      "Epoch 7/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 737us/step - accuracy: 0.5213 - loss: 1.5286 - val_accuracy: 0.5911 - val_loss: 1.4186\n",
      "Epoch 8/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5400 - loss: 1.4548 - val_accuracy: 0.5979 - val_loss: 1.3668\n",
      "Epoch 9/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.5588 - loss: 1.3996 - val_accuracy: 0.5911 - val_loss: 1.3388\n",
      "Epoch 10/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - accuracy: 0.5736 - loss: 1.3687 - val_accuracy: 0.6163 - val_loss: 1.3230\n",
      "Epoch 11/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.5746 - loss: 1.3306 - val_accuracy: 0.6334 - val_loss: 1.2838\n",
      "Epoch 12/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.5896 - loss: 1.2938 - val_accuracy: 0.6403 - val_loss: 1.2637\n",
      "Epoch 13/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - accuracy: 0.5952 - loss: 1.2614 - val_accuracy: 0.6449 - val_loss: 1.2318\n",
      "Epoch 14/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.6022 - loss: 1.2430 - val_accuracy: 0.6369 - val_loss: 1.2351\n",
      "Epoch 15/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.6088 - loss: 1.2076 - val_accuracy: 0.6472 - val_loss: 1.2188\n",
      "Epoch 16/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.6185 - loss: 1.1873 - val_accuracy: 0.6392 - val_loss: 1.2122\n",
      "Epoch 17/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6336 - loss: 1.1486 - val_accuracy: 0.6690 - val_loss: 1.1987\n",
      "Epoch 18/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.6238 - loss: 1.1498 - val_accuracy: 0.6552 - val_loss: 1.2210\n",
      "Epoch 19/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.6324 - loss: 1.1128 - val_accuracy: 0.6518 - val_loss: 1.1769\n",
      "Epoch 20/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.6327 - loss: 1.1195 - val_accuracy: 0.6655 - val_loss: 1.1730\n",
      "Epoch 21/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.6382 - loss: 1.1081 - val_accuracy: 0.6598 - val_loss: 1.1791\n",
      "Epoch 22/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - accuracy: 0.6523 - loss: 1.0765 - val_accuracy: 0.6609 - val_loss: 1.1825\n",
      "Epoch 23/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.6562 - loss: 1.0669 - val_accuracy: 0.6701 - val_loss: 1.1578\n",
      "Epoch 24/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.6584 - loss: 1.0626 - val_accuracy: 0.6529 - val_loss: 1.1979\n",
      "Epoch 25/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.6658 - loss: 1.0362 - val_accuracy: 0.6701 - val_loss: 1.1666\n",
      "Epoch 26/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.6609 - loss: 1.0446 - val_accuracy: 0.6552 - val_loss: 1.1887\n",
      "Epoch 27/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6766 - loss: 0.9953 - val_accuracy: 0.6472 - val_loss: 1.1658\n",
      "Epoch 28/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.6773 - loss: 1.0035 - val_accuracy: 0.6415 - val_loss: 1.1848\n",
      "Final validation accuracy: 0.6701\n",
      "\n",
      "Melhores hiperparâmetros usados no treinamento:\n",
      "Arquitetura: {'hidden_units': [128, 64, 32], 'activation': 'tanh'}\n",
      "Configuração de tuning: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.0001, 'dropout_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Definir o modelo final com os melhores parâmetros encontrados\n",
    "def final_train_model(best_architecture, best_tuning_config, files):\n",
    "    # Carregar dados\n",
    "    X_val, y_val = load_fold_data(0, files)  # Dados de validação\n",
    "    X_train, y_train = [], []\n",
    "    for j in range(1, 10):  # Usando os outros folds para treino\n",
    "        X_temp, y_temp = load_fold_data(j, files)\n",
    "        X_train.append(X_temp)\n",
    "        y_train.append(y_temp)\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "    # Construir o modelo com a arquitetura e os hiperparâmetros finais\n",
    "    model = MLP(\n",
    "        input_dim=X_train.shape[1],\n",
    "        output_dim=10,  # Ajuste para número de classes (10)\n",
    "        hidden_units=best_architecture['hidden_units'],\n",
    "        activation=best_architecture['activation']\n",
    "    )\n",
    "    \n",
    "    # Compilar o modelo\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=best_tuning_config['learning_rate']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Definir callbacks de regularização\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Treinar o modelo\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=best_tuning_config['batch_size'],\n",
    "        epochs=best_tuning_config['epochs'],\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Avaliar o modelo final\n",
    "    final_accuracy = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    print(f\"Final validation accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "    # Imprimir os melhores hiperparâmetros após o treinamento\n",
    "    print(\"\\nMelhores hiperparâmetros usados no treinamento:\")\n",
    "    print(f\"Arquitetura: {best_architecture}\")\n",
    "    print(f\"Configuração de tuning: {best_tuning_config}\")\n",
    "\n",
    "# Usando os melhores parâmetros encontrados\n",
    "best_architecture = {'hidden_units': [128, 64, 32], 'activation': 'tanh'}\n",
    "best_tuning_config = {\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.0001,\n",
    "    'dropout_rate': 0.1\n",
    "}\n",
    "\n",
    "# Carregar os arquivos de dados (ajustar conforme o caminho correto)\n",
    "files = [f'datasets/urbansounds_features_fold{i}.csv' for i in range(1, 11)]\n",
    "\n",
    "# Treinar o modelo com os melhores hiperparâmetros encontrados\n",
    "final_train_model(best_architecture, best_tuning_config, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franciscamihalache/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.0988 - loss: 2.3518 - val_accuracy: 0.3219 - val_loss: 2.1218\n",
      "Epoch 2/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.2189 - loss: 2.1499 - val_accuracy: 0.4570 - val_loss: 1.9662\n",
      "Epoch 3/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.3117 - loss: 2.0179 - val_accuracy: 0.4891 - val_loss: 1.8180\n",
      "Epoch 4/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.3625 - loss: 1.9027 - val_accuracy: 0.5155 - val_loss: 1.6871\n",
      "Epoch 5/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.4075 - loss: 1.7900 - val_accuracy: 0.5315 - val_loss: 1.5818\n",
      "Epoch 6/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.4492 - loss: 1.6801 - val_accuracy: 0.5487 - val_loss: 1.4986\n",
      "Epoch 7/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.4707 - loss: 1.6202 - val_accuracy: 0.5567 - val_loss: 1.4347\n",
      "Epoch 8/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.4907 - loss: 1.5483 - val_accuracy: 0.5865 - val_loss: 1.3805\n",
      "Epoch 9/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.5254 - loss: 1.4852 - val_accuracy: 0.5956 - val_loss: 1.3429\n",
      "Epoch 10/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.5219 - loss: 1.4486 - val_accuracy: 0.6186 - val_loss: 1.3030\n",
      "Epoch 11/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5531 - loss: 1.3782 - val_accuracy: 0.6380 - val_loss: 1.2845\n",
      "Epoch 12/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.5585 - loss: 1.3674 - val_accuracy: 0.6438 - val_loss: 1.2578\n",
      "Epoch 13/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.5753 - loss: 1.3257 - val_accuracy: 0.6529 - val_loss: 1.2326\n",
      "Epoch 14/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.5777 - loss: 1.2910 - val_accuracy: 0.6369 - val_loss: 1.2223\n",
      "Epoch 15/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.5985 - loss: 1.2556 - val_accuracy: 0.6392 - val_loss: 1.2118\n",
      "Epoch 16/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - accuracy: 0.5989 - loss: 1.2484 - val_accuracy: 0.6541 - val_loss: 1.1843\n",
      "Epoch 17/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.6139 - loss: 1.2129 - val_accuracy: 0.6483 - val_loss: 1.1863\n",
      "Epoch 18/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6116 - loss: 1.1971 - val_accuracy: 0.6678 - val_loss: 1.1649\n",
      "Epoch 19/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.6180 - loss: 1.1807 - val_accuracy: 0.6483 - val_loss: 1.1597\n",
      "Epoch 20/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.6274 - loss: 1.1553 - val_accuracy: 0.6598 - val_loss: 1.1577\n",
      "Epoch 21/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.6286 - loss: 1.1415 - val_accuracy: 0.6575 - val_loss: 1.1559\n",
      "Epoch 22/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.6289 - loss: 1.1253 - val_accuracy: 0.6575 - val_loss: 1.1549\n",
      "Epoch 23/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6313 - loss: 1.1131 - val_accuracy: 0.6609 - val_loss: 1.1553\n",
      "Epoch 24/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.6337 - loss: 1.1211 - val_accuracy: 0.6621 - val_loss: 1.1483\n",
      "Epoch 25/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.6458 - loss: 1.0813 - val_accuracy: 0.6472 - val_loss: 1.1737\n",
      "Epoch 26/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.6447 - loss: 1.0894 - val_accuracy: 0.6701 - val_loss: 1.1351\n",
      "Epoch 27/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.6538 - loss: 1.0789 - val_accuracy: 0.6781 - val_loss: 1.1539\n",
      "Epoch 28/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.6514 - loss: 1.0675 - val_accuracy: 0.6735 - val_loss: 1.1719\n",
      "Epoch 29/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.6633 - loss: 1.0327 - val_accuracy: 0.6644 - val_loss: 1.1665\n",
      "Epoch 30/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.6586 - loss: 1.0405 - val_accuracy: 0.6678 - val_loss: 1.1590\n",
      "Epoch 31/50\n",
      "\u001b[1m123/123\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6632 - loss: 1.0166 - val_accuracy: 0.6632 - val_loss: 1.1931\n",
      "Final validation accuracy: 0.6632\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Função para carregar os dados (ajuste conforme necessário para seu caso)\n",
    "def load_fold_data(fold, files):\n",
    "    # Carregar os dados de cada \"fold\" (assumindo CSVs ou outros formatos)\n",
    "    data = pd.read_csv(files[fold])\n",
    "    X = data.drop('Label', axis=1).values  # Ajuste conforme a estrutura dos seus dados\n",
    "    y = data['Label'].values  # Ajuste conforme a estrutura dos seus dados\n",
    "    return X, y\n",
    "\n",
    "# Função de treinamento do MLP\n",
    "def train_MLP(mlp_model, train_data, train_labels, test_data, test_labels, patience, batch_size, num_epochs):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "    history = mlp_model.fit(train_data, train_labels,\n",
    "                            epochs=num_epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[early_stopping],\n",
    "                            validation_data=(test_data, test_labels),\n",
    "                            verbose=1)\n",
    "    return history\n",
    "\n",
    "# Função para treinar o modelo final com os melhores parâmetros\n",
    "def final_train_model(best_architecture, best_tuning_config, files):\n",
    "    # Carregar dados\n",
    "    X_val, y_val = load_fold_data(0, files)  # Dados de validação\n",
    "    X_train, y_train = [], []\n",
    "    for j in range(1, 10):  # Usando os outros folds para treino\n",
    "        X_temp, y_temp = load_fold_data(j, files)\n",
    "        X_train.append(X_temp)\n",
    "        y_train.append(y_temp)\n",
    "    X_train = np.concatenate(X_train, axis=0)\n",
    "    y_train = np.concatenate(y_train, axis=0)\n",
    "\n",
    "    # Construir o modelo com a arquitetura e os hiperparâmetros finais\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(X_train.shape[1],)))\n",
    "    \n",
    "    # Adicionar camadas ocultas conforme a melhor arquitetura\n",
    "    for units in best_architecture['hidden_units']:\n",
    "        model.add(tf.keras.layers.Dense(units, activation=best_architecture['activation']))\n",
    "        model.add(tf.keras.layers.Dropout(best_tuning_config['dropout_rate']))\n",
    "    \n",
    "    # Camada de saída\n",
    "    model.add(tf.keras.layers.Dense(10, activation='softmax'))  # Ajuste conforme o número de classes\n",
    "    \n",
    "    # Compilar o modelo\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=best_tuning_config['learning_rate']),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Treinar o modelo\n",
    "    history = train_MLP(\n",
    "        mlp_model=model,\n",
    "        train_data=X_train,\n",
    "        train_labels=y_train,\n",
    "        test_data=X_val,\n",
    "        test_labels=y_val,\n",
    "        patience=5,  # Define a paciência para early stopping\n",
    "        batch_size=best_tuning_config['batch_size'],\n",
    "        num_epochs=best_tuning_config['epochs']\n",
    "    )\n",
    "\n",
    "    # Avaliar o modelo final\n",
    "    final_accuracy = model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "    print(f\"Final validation accuracy: {final_accuracy:.4f}\")\n",
    "\n",
    "# Usando os melhores parâmetros encontrados\n",
    "best_architecture = {'hidden_units': [128, 64, 32], 'activation': 'tanh'}\n",
    "best_tuning_config = {\n",
    "    'batch_size': 64,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 0.0001,\n",
    "    'dropout_rate': 0.1\n",
    "}\n",
    "\n",
    "# Carregar os arquivos de dados (ajustar conforme o caminho correto)\n",
    "files = [f'datasets/urbansounds_features_fold{i}.csv' for i in range(1, 11)]\n",
    "\n",
    "# Treinar o modelo com os melhores hiperparâmetros encontrados\n",
    "final_train_model(best_architecture, best_tuning_config, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
